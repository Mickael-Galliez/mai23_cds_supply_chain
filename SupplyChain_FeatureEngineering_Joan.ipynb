{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1533c41c",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6f2dc",
   "metadata": {},
   "source": [
    "## Libraries & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc89cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Je narrivait pas a installer la librairy textBlob depuis la UI Anaconda\n",
    "# Les 3 lignes ci-dessous sont a faire tourner une seule fois:\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install textblob\n",
    "# !{sys.executable} -m pip install textblob_fr\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fileName = 'df_complet.csv'\n",
    "pathName = './Data'\n",
    "\n",
    "\n",
    "# df=pd.read_excel(f'{pathName}\\{fileName}')\n",
    "df=pd.read_csv(f'{pathName}/{fileName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d190758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Client', 'Nombre_avis_publie', 'Note',\n",
      "       'Titres', 'Commentaire', 'Date_experience', 'Date_publication',\n",
      "       'Reponse', 'Date_reponse', 'Pays', 'Verifications', 'Entreprise',\n",
      "       'longCommentaire', 'longTitres', 'nb_Mots_Commentaire',\n",
      "       'nb_Mots_Titres'],\n",
      "      dtype='object')\n",
      "Commentaire NAN: 0\n",
      "Commentaire Null: 0\n",
      "Titres NAN: 0\n",
      "Nombre_avis_publie NAN: 0\n",
      "Verifications NAN: 0\n",
      "Date_experience NAN: 0\n",
      "Date_publication NAN: 0\n",
      "\n",
      "Nombres de lignes: 285983\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suppression des valeurs NaN dans Titres et commentaires\n",
    "df = df.dropna(subset=['Commentaire','Titres'],how='all')\n",
    "df['Commentaire'] = df['Commentaire'].fillna('')\n",
    "df['Titres'] = df['Titres'].fillna('')\n",
    "\n",
    "#Suppression des lignes avec Titres et commentaire egale a '' (string vide):\n",
    "df = df.drop(df[(df.Commentaire == '') & (df.Titres == '')].index)\n",
    "\n",
    "# Suppresion des Lignes redondantes:\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#df = df.drop(df.loc[df.Titres.apply(lambda x: not(isinstance(x, str)))].index)\n",
    "print(df.columns)\n",
    "df.reset_index()\n",
    "\n",
    "#Convertir toutes les valeurs de Commentaire et Titre en Object:string:\n",
    "df['Commentaire'] = df['Commentaire'].astype(str)\n",
    "df['Titres'] = df['Titres'].astype(str)\n",
    "\n",
    "# Remplacement des characteres non ASCII:\n",
    "items = {\"ä\": \"a\", \"ç\": \"c\", \"è\": \"e\", \"º\": \"\", \"Ã\": \"A\", \"Í\": \"I\", \"í\": \"i\", \"Ü\": \"U\", \"â\": \"a\", \"ò\": \"o\", \"¿\": \"\",\n",
    "             \"ó\": \"o\", \"á\": \"a\", \"à\": \"a\", \"õ\": \"o\", \"¡\": \"\", \"Ó\": \"O\", \"ù\": \"u\", \"Ú\": \"U\", \"´\": \"\", \"Ñ\": \"N\", \"Ò\": \"O\",\n",
    "             \"ï\": \"i\", \"Ï\": \"I\", \"Ç\": \"C\", \"À\": \"A\", \"É\": \"E\", \"ë\": \"e\", \"Á\": \"A\", \"ã\": \"a\", \"Ö\": \"O\", \"ú\": \"u\",\n",
    "             \"ñ\": \"n\", \"é\": \"e\", \"ê\": \"e\", \"·\": \"-\", \"ª\": \"a\", \"°\": \"\", \"ü\": \"u\", \"ô\": \"o\",\"+\":\"plus\",\"-\":\"moins\",\"_\":\" \"}\n",
    "\n",
    "df['Commentaire'] = df['Commentaire'].str.replace(r'[^\\x00-\\x7F]', lambda x: items.get(x.group(0)) or '_', regex=True)\n",
    "df['Titres'] = df['Titres'].str.replace(r'[^\\x00-\\x7F]', lambda x: items.get(x.group(0)) or '_', regex=True)\n",
    "\n",
    "# Conversion des date en objet datetime:\n",
    "df.Date_experience =  pd.to_datetime(df.Date_experience)\n",
    "df.Date_publication =  pd.to_datetime(df.Date_publication)\n",
    "\n",
    "print(f'Commentaire NAN: {df.Commentaire.isna().sum()}')\n",
    "print(f'Commentaire Null: {df.Commentaire.isnull().sum()}')\n",
    "print(f'Titres NAN: {df.Titres.isna().sum()}')\n",
    "print(f'Nombre_avis_publie NAN: {df.Nombre_avis_publie.isna().sum()}')\n",
    "print(f'Verifications NAN: {df.Verifications.isna().sum()}')\n",
    "print(f'Date_experience NAN: {df.Date_experience.isna().sum()}')\n",
    "print(f'Date_publication NAN: {df.Date_publication.isna().sum()}')\n",
    "\n",
    "print(f'\\nNombres de lignes: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c86ee",
   "metadata": {},
   "source": [
    "## Commentaires et Titre "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fe5f7",
   "metadata": {},
   "source": [
    "### Nombres de mots et characteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18ca2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['longCommentaire']  = df.Commentaire.apply(lambda x: len(x))\n",
    "df['longTitres']  = df.Titres.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bef08438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_Mots_Commentaire']  = df.Commentaire.apply(lambda x: len(x.split(' ')))\n",
    "df['nb_Mots_Titres']  = df.Titres.apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7391ff4",
   "metadata": {},
   "source": [
    "### Ponctuations, nombres, characteres speciaux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a005d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_special(str):\n",
    "    upper, lower, number, ponctuation, special = 0, 0, 0, 0, 0\n",
    "    for i in range(len(str)):\n",
    "        if str[i].isupper():\n",
    "            upper += 1\n",
    "        elif str[i].islower():\n",
    "            lower += 1\n",
    "        elif str[i].isdigit():\n",
    "            number += 1\n",
    "        elif str[i] in ['!','?']:\n",
    "            ponctuation += 1\n",
    "            \n",
    "        elif str[i] in '@#$%&+=-<>~/\\\"*(){}[]':\n",
    "            special += 1\n",
    "#     print('Upper case letters:', upper)\n",
    "#     print('Lower case letters:', lower)\n",
    "#     print('Number:', number)\n",
    "#     print('Ponctuation:', ponctuation)\n",
    "#     print('Special characters:', special)\n",
    "    \n",
    "    return upper,lower,number,ponctuation,special\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2d7d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_majuscules_Commentaire'], _, df['nb_chiffres_Commentaire'], df['nb_ponctuation_Commentaire'],df['nb_special_Commentaire'] = zip(*df.Commentaire.apply(lambda x: Count_special(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbe3d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_majuscules_Titre'], _, df['nb_chiffres_Titre'], df['nb_ponctuation_Titre'],df['nb_special_Titre'] = zip(*df.Titres.apply(lambda x: Count_special(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35abda0",
   "metadata": {},
   "source": [
    "### Mots Clefs: (A terminer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93c6a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_ngram(corpus, n=None, ngrame=1,stopWord=True):\n",
    "    \"\"\"\n",
    "    Compte le nombre de recurrences des ngrames presents dans le corpus et retourne le top n ngrames et leur decomptes.\n",
    "\n",
    "    :param corpus: Serie, incluant 1 seul colonne de string\n",
    "    :param n: int, Nombre de Ngrame a collecter apres triage\n",
    "    :param ngrame: int, ordre du Ngrame vise. 1 mot = 1grame, couple mots se suivant = 2grame, etc\n",
    "    :param stopWord: Boolean, filtre les stopWord present dans les string. La list de stop word est definie dans la\n",
    "    fonction. StopWord example = le,la,les,de,je,etc\n",
    "    :return: List of tuple, [(mot,nombre recense)]\n",
    "    \"\"\"\n",
    "\n",
    "    items = {\"ä\": \"a\", \"ç\": \"c\", \"è\": \"e\", \"º\": \"\", \"Ã\": \"A\", \"Í\": \"I\", \"í\": \"i\", \"Ü\": \"U\", \"â\": \"a\", \"ò\": \"o\", \"¿\": \"\",\n",
    "             \"ó\": \"o\", \"á\": \"a\", \"à\": \"a\", \"õ\": \"o\", \"¡\": \"\", \"Ó\": \"O\", \"ù\": \"u\", \"Ú\": \"U\", \"´\": \"\", \"Ñ\": \"N\", \"Ò\": \"O\",\n",
    "             \"ï\": \"i\", \"Ï\": \"I\", \"Ç\": \"C\", \"À\": \"A\", \"É\": \"E\", \"ë\": \"e\", \"Á\": \"A\", \"ã\": \"a\", \"Ö\": \"O\", \"ú\": \"u\",\n",
    "             \"ñ\": \"n\", \"é\": \"e\", \"ê\": \"e\", \"·\": \"-\", \"ª\": \"a\", \"°\": \"\", \"ü\": \"u\", \"ô\": \"o\",\"+\":\"plus\",\"-\":\"moins\",\"_\":\" \"}\n",
    "\n",
    "    stopWordFrench = ['alors','au','ai','aucuns','aussi','autre','avant','avec','avoir','bon','car','ce','cela',\n",
    "                      'ces','ceux','chaque','ci','comme','comment','dans','de','des','du','dedans','dehors','depuis',\n",
    "                      'devrait','doit','donc','dos','debut','elle','elles','en','encore','essai','est','et','eu',\n",
    "                      'fait','faites','fois','font','hors','ici','il','ils','je','juste','la','le','les','leur','ma',\n",
    "                      'maintenant','mais','mes','mien','moins','mon','mot','meme','ni','nommes','notre','nous','ou',\n",
    "                      'par','parce','peut','plupart','pour','pourquoi','quand','que','quel','quelle','quelles',\n",
    "                      'quels','qui','sa','sans','ses','seulement','si','sien','son','sont','sous','soyez','sujet',\n",
    "                      'sur','ta','un','une','tandis','tellement','tels','tes','ton','tous','tout','tres','tu',\n",
    "                      'voient','vont','votre','vous','vu','ca','etaient','etat','etions','ete','etre','me','chez',\n",
    "                      'on','ont',\"de_\",\"et_\",\"la_\",\"le_\",\"j_ai\",\"j_\"]\n",
    "\n",
    "    stopWord = stopWordFrench if stopWord else None\n",
    "\n",
    "    corpus = corpus.str.replace(r'[^\\x00-\\x7F]', lambda x: items.get(x.group(0)) or '_', regex=True)\n",
    "\n",
    "    vec = CountVectorizer(ngram_range=(ngrame, ngrame), stop_words=stopWord).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3afdfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('toujours pas', 4905), ('commande pneus', 2493), ('pas recu', 2481), ('service client', 2187), ('ne pas', 2118)]\n",
      "[('toujours pas', 4905), ('commande pneus', 2493), ('pas recu', 2481), ('service client', 2187), ('ne pas', 2118), ('toujours pas', 914), ('commande pneus', 576), ('ne pas', 575), ('pas recu', 423), ('service client', 372)]\n",
      "[('toujours pas', 4905), ('commande pneus', 2493), ('pas recu', 2481), ('service client', 2187), ('ne pas', 2118), ('toujours pas', 914), ('commande pneus', 576), ('ne pas', 575), ('pas recu', 423), ('service client', 372), ('ne pas', 723), ('delai livraison', 656), ('commande pneus', 569), ('livraison rapide', 474), ('centre montage', 458)]\n",
      "[('toujours pas', 4905), ('commande pneus', 2493), ('pas recu', 2481), ('service client', 2187), ('ne pas', 2118), ('toujours pas', 914), ('commande pneus', 576), ('ne pas', 575), ('pas recu', 423), ('service client', 372), ('ne pas', 723), ('delai livraison', 656), ('commande pneus', 569), ('livraison rapide', 474), ('centre montage', 458), ('livraison rapide', 4561), ('qualite prix', 1766), ('rapport qualite', 1516), ('delai livraison', 1322), ('rien dire', 1081)]\n",
      "[('toujours pas', 4905), ('commande pneus', 2493), ('pas recu', 2481), ('service client', 2187), ('ne pas', 2118), ('toujours pas', 914), ('commande pneus', 576), ('ne pas', 575), ('pas recu', 423), ('service client', 372), ('ne pas', 723), ('delai livraison', 656), ('commande pneus', 569), ('livraison rapide', 474), ('centre montage', 458), ('livraison rapide', 4561), ('qualite prix', 1766), ('rapport qualite', 1516), ('delai livraison', 1322), ('rien dire', 1081), ('livraison rapide', 31794), ('qualite prix', 8288), ('rapport qualite', 6906), ('rien dire', 5656), ('rien redire', 4307)]\n"
     ]
    }
   ],
   "source": [
    "ngrame=2\n",
    "common_words=[]\n",
    "for note in range(1,6):\n",
    "    common_words += get_top_ngram(df.loc[df.Note==note]['Commentaire'], n=5,ngrame=ngrame,stopWord=True)\n",
    "\n",
    "    print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af64316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toujours pas', 'commande pneus', 'pas recu', 'service client', 'ne pas', 'delai livraison', 'livraison rapide', 'centre montage', 'qualite prix', 'rapport qualite', 'rien dire', 'rien redire']\n"
     ]
    }
   ],
   "source": [
    "wordOnlyList=[x[0] for x in common_words]\n",
    "\n",
    "#Conserve les strings unique\n",
    "selected_words= []\n",
    "[selected_words.append(x) for x in wordOnlyList if x not in selected_words]\n",
    "\n",
    "print(selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0011a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['Commentaire']\n",
    "\n",
    "items = {\"ä\": \"a\", \"ç\": \"c\", \"è\": \"e\", \"º\": \"\", \"Ã\": \"A\", \"Í\": \"I\", \"í\": \"i\", \"Ü\": \"U\", \"â\": \"a\", \"ò\": \"o\", \"¿\": \"\",\n",
    "         \"ó\": \"o\", \"á\": \"a\", \"à\": \"a\", \"õ\": \"o\", \"¡\": \"\", \"Ó\": \"O\", \"ù\": \"u\", \"Ú\": \"U\", \"´\": \"\", \"Ñ\": \"N\", \"Ò\": \"O\",\n",
    "         \"ï\": \"i\", \"Ï\": \"I\", \"Ç\": \"C\", \"À\": \"A\", \"É\": \"E\", \"ë\": \"e\", \"Á\": \"A\", \"ã\": \"a\", \"Ö\": \"O\", \"ú\": \"u\",\n",
    "         \"ñ\": \"n\", \"é\": \"e\", \"ê\": \"e\", \"·\": \"-\", \"ª\": \"a\", \"°\": \"\", \"ü\": \"u\", \"ô\": \"o\",\"+\":\"plus\",\"-\":\"moins\",\"_\":\" \"}\n",
    "\n",
    "stopWordFrench = ['alors','au','ai','aucuns','aussi','autre','avant','avec','avoir','bon','car','ce','cela',\n",
    "                  'ces','ceux','chaque','ci','comme','comment','dans','de','des','du','dedans','dehors','depuis',\n",
    "                  'devrait','doit','donc','dos','debut','elle','elles','en','encore','essai','est','et','eu',\n",
    "                  'fait','faites','fois','font','hors','ici','il','ils','je','juste','la','le','les','leur','ma',\n",
    "                  'maintenant','mais','mes','mien','moins','mon','mot','meme','ni','nommes','notre','nous','ou',\n",
    "                  'par','parce','peut','plupart','pour','pourquoi','quand','que','quel','quelle','quelles',\n",
    "                  'quels','qui','sa','sans','ses','seulement','si','sien','son','sont','sous','soyez','sujet',\n",
    "                  'sur','ta','un','une','tandis','tellement','tels','tes','ton','tous','tout','tres','tu',\n",
    "                  'voient','vont','votre','vous','vu','ca','etaient','etat','etions','ete','etre','me','chez',\n",
    "                  'on','ont',\"de_\",\"et_\",\"la_\",\"le_\",\"j_ai\",\"j_\"]\n",
    "\n",
    "\n",
    "corpus = corpus.str.replace(r'[^\\x00-\\x7F]', lambda x: items.get(x.group(0)) or '_', regex=True)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(ngrame, ngrame), stop_words=stopWordFrench).fit(corpus)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1c909ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675978\n"
     ]
    }
   ],
   "source": [
    "print(vec.vocabulary_['toujours pas'])\n",
    "bag_of_words = vec.transform(corpus)\n",
    "\n",
    "ngramecount = [bag_of_words[i,vec.vocabulary_['toujours pas']] if 'toujours pas' in vec.vocabulary_.keys() else 0 for i in range(len(df))]\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(bag_of_words[i,vec.vocabulary_['toujours pas']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b5be8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285983\n",
      "        Unnamed: 0.1  Unnamed: 0             Client  Nombre_avis_publie  Note  \\\n",
      "760              760         760  Maurice Bouzonnet                   3     1   \n",
      "1206            1206        1206    Jean Max Barret                   2     1   \n",
      "1625            1625        1625      Murielle BOUR                   2     2   \n",
      "2492            2492        2492            Le Meur                  10     1   \n",
      "3197            3197        3197       lolo laurent                  26     1   \n",
      "...              ...         ...                ...                 ...   ...   \n",
      "276158        276158      276158        Ahmed SFERI                   2     1   \n",
      "276776        276776      276776  Sébastien  Tracol                   1     1   \n",
      "278399        278399      278399     rodrigue motyl                   1     1   \n",
      "279541        279541      279541       Dylan Fohrer                   1     1   \n",
      "285013        285013      285013             Client                   1     1   \n",
      "\n",
      "                                          Titres  \\\n",
      "760                                 Pas serieux,   \n",
      "1206    J'ai commande 4 pneus pour mes motos et_   \n",
      "1625                                 Cafouillage   \n",
      "2492        Commande le 21 avril de 4 pneus sur_   \n",
      "3197                         Mauvaise experience   \n",
      "...                                          ...   \n",
      "276158                          Avis sur le site   \n",
      "276776  Je devais recevoir mes pneus sous 3 ou _   \n",
      "278399      Bonjour J'ai commande et paye  mes _   \n",
      "279541  Le transporteur ne m'a pas livre comme _   \n",
      "285013                      Pas recu la commande   \n",
      "\n",
      "                                              Commentaire Date_experience  \\\n",
      "760     Pas livre, commande en preparation depuis plus...      2023-07-09   \n",
      "1206    J'ai commande 4 pneus pour mes motos et j'ai r...      2023-07-04   \n",
      "1625    Les pneus ont pas ete notes __livres au garage...      2023-06-15   \n",
      "2492    Commande le 21 avril de 4 pneus sur Allopneus....      2023-05-22   \n",
      "3197    Premiere commande ( numero 60308744) 4 pneus M...      2023-05-03   \n",
      "...                                                   ...             ...   \n",
      "276158  bonjour a tous,puisqu'il m'est donne l'opportu...      2017-11-24   \n",
      "276776  Je devais recevoir mes pneus sous 3 ou 5 jours...      2017-10-28   \n",
      "278399  Bonjour J'ai commande et paye  mes pneus  par ...      2017-07-17   \n",
      "279541  Le transporteur ne m'a pas livre comme il le d...      2017-05-07   \n",
      "285013  Cela fait 10 jours que la commande est faite e...      2016-01-06   \n",
      "\n",
      "       Date_publication                                            Reponse  \\\n",
      "760          2023-07-28  Bonjour Maurice, Je suis navré d'apprendre vot...   \n",
      "1206         2023-07-08  Bonjour Jean-Max, Je suis navrée d'apprendre v...   \n",
      "1625         2023-06-30  Bonjour Murielle, Je suis navrée d'apprendre v...   \n",
      "2492         2023-05-24  Bonjour, Je suis navrée d'apprendre votre mésa...   \n",
      "3197         2023-06-20  Bonjour Laurent, Je suis navrée pour la gêne o...   \n",
      "...                 ...                                                ...   \n",
      "276158       2017-11-24  Bonjour, Nous vous remercions pour votre messa...   \n",
      "276776       2017-10-28  Bonjour, Nous vous remercions pour votre messa...   \n",
      "278399       2017-07-17  Bonjour,Nous vous remercions pour votre messag...   \n",
      "279541       2017-05-07  Bonjour, Nous vous remercions pour votre messa...   \n",
      "285013       2016-01-06  Bonjour,  Nous faisons suite à votre message c...   \n",
      "\n",
      "        ... Pays Verifications     Entreprise longCommentaire  longTitres  \\\n",
      "760     ...   FR             0     Allopneus              322          12   \n",
      "1206    ...   RE             1     Allopneus              247          40   \n",
      "1625    ...   FR             1     Allopneus              677          11   \n",
      "2492    ...   FR             0     Allopneus             1449          36   \n",
      "3197    ...   FR             0     Allopneus             1498          19   \n",
      "...     ...  ...           ...            ...             ...         ...   \n",
      "276158  ...   RE             1  Pneus Online              766          16   \n",
      "276776  ...   FR             1  Pneus Online              673          40   \n",
      "278399  ...   FR             1  Pneus Online              378          36   \n",
      "279541  ...   FR             0  Pneus Online              335          40   \n",
      "285013  ...   FR             1  Pneus Online              214          20   \n",
      "\n",
      "        nb_Mots_Commentaire  nb_Mots_Titres  Saison_experience  \\\n",
      "760                      53               2                  3   \n",
      "1206                     52               8                  3   \n",
      "1625                    124               1                  3   \n",
      "2492                    259               8                  2   \n",
      "3197                    263               2                  2   \n",
      "...                     ...             ...                ...   \n",
      "276158                  132               4                  4   \n",
      "276776                  122               9                  4   \n",
      "278399                   60               8                  3   \n",
      "279541                   60               8                  2   \n",
      "285013                   41               4                  1   \n",
      "\n",
      "        polarity_Commentaire  polarity_Titres  \n",
      "760                 0.183333           -0.225  \n",
      "1206                0.225000            0.000  \n",
      "1625               -0.175000            0.000  \n",
      "2492                0.016413            0.000  \n",
      "3197                0.045417           -0.710  \n",
      "...                      ...              ...  \n",
      "276158              0.100000            0.000  \n",
      "276776              0.173333            0.000  \n",
      "278399              0.164583            0.000  \n",
      "279541             -0.500000            0.000  \n",
      "285013              0.000000            0.000  \n",
      "\n",
      "[285 rows x 21 columns]\n",
      "Pas livre, commande en preparation depuis plus de 9 jours. Pourtant pneus dispo sur le site.Ne repond pas aux mails, le chat ne fonctionne pas.Toujours pas livre le 24/07.....La mise en _uvre est a revoir, que tu baratin, expedie depuis le 20 soit disant.!Le 28/07 toujours pas de nouvelle du colis.!Malgre vos recherches.\n"
     ]
    }
   ],
   "source": [
    "print(len(ngramecount))\n",
    "print(df[[x == 2 for x in ngramecount]])\n",
    "\n",
    "print(df.loc[760,'Commentaire'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c829cb",
   "metadata": {},
   "source": [
    "### Sentiment Polarity (TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c1bb286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joan\\AppData\\Local\\Temp\\ipykernel_15264\\899469321.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
      "C:\\Users\\joan\\AppData\\Local\\Temp\\ipykernel_15264\\899469321.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
      "C:\\Users\\joan\\AppData\\Local\\Temp\\ipykernel_15264\\899469321.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ReviewText = ReviewText.str.replace('(&amp)', '')\n",
      "C:\\Users\\joan\\AppData\\Local\\Temp\\ipykernel_15264\\899469321.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ReviewText = ReviewText.str.replace('(&gt)', '')\n",
      "C:\\Users\\joan\\AppData\\Local\\Temp\\ipykernel_15264\\899469321.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ReviewText = ReviewText.str.replace('(&lt)', '')\n",
      "C:\\Users\\joan\\AppData\\Local\\Temp\\ipykernel_15264\\899469321.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ReviewText = ReviewText.str.replace('(\\xa0)', ' ')\n"
     ]
    }
   ],
   "source": [
    "# Code:\n",
    "\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "#print(df.loc[df.Commentaire.apply(lambda x: not(isinstance(x, str)))].head())\n",
    "# df = df.drop(df.loc[df.Commentaire.apply(lambda x: not(isinstance(x, str)))].index)\n",
    "# df.reset_index()\n",
    "#df.info()\n",
    "\n",
    "# Definit objet blobber et configure les modeles francais\n",
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "# Fonction nettoyant le text\n",
    "def preprocess(ReviewText):\n",
    "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')\n",
    "    return ReviewText\n",
    "\n",
    "\n",
    "df['Titres'] = preprocess(df['Titres'])\n",
    "df['Commentaire'] = preprocess(df['Commentaire'])\n",
    "df['polarity_Commentaire'] = df['Commentaire'].map(lambda text: tb(text).sentiment[0])\n",
    "df['polarity_Titres'] = df['Titres'].map(lambda text: tb(text).sentiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472129df",
   "metadata": {},
   "source": [
    "### Date Experience transforme en saison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bba6fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "df['Saison_experience'] = df.Date_experience.apply(lambda x: x.month%12 // 3 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f61a8d",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb414e6",
   "metadata": {},
   "source": [
    "### Details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe059d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Client', 'Nombre_avis_publie', 'Note',\n",
      "       'Titres', 'Commentaire', 'Date_experience', 'Date_publication',\n",
      "       'Reponse', 'Date_reponse', 'Pays', 'Verifications', 'Entreprise',\n",
      "       'longCommentaire', 'longTitres', 'nb_Mots_Commentaire',\n",
      "       'nb_Mots_Titres', 'Saison_experience', 'polarity_Commentaire',\n",
      "       'polarity_Titres', 'nb_majuscules_Commentaire',\n",
      "       'nb_chiffres_Commentaire', 'nb_ponctuation_Commentaire',\n",
      "       'nb_special_Commentaire', 'nb_majuscules_Titre', 'nb_chiffres_Titre',\n",
      "       'nb_ponctuation_Titre', 'nb_special_Titre'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6a595",
   "metadata": {},
   "source": [
    "### Matrice de correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ab0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, chi2_contingency\n",
    "print(df.columns)\n",
    "\n",
    "catVar=['Nombre_avis_publie','Pays','Verifications','Entreprise','Date_experience','Date_publication','Note']\n",
    "# catVar=['Nombre_avis_publie','Pays','Verifications','Entreprise','Date_experience','Date_publication','longCommentaire','longTitre','polarity','Note']\n",
    "#catVar=['Nombre_avis_publie','Pays']\n",
    "\n",
    "stat =[]\n",
    "pval = []\n",
    "dofs =[]\n",
    "corr=[]\n",
    "\n",
    "for col in catVar:\n",
    "    stat_sub =[]\n",
    "    pval_sub = []\n",
    "    dofs_sub =[]\n",
    "    corr_sub=[]\n",
    "    for col2 in catVar:\n",
    "        ct = pd.crosstab(df[col],df[col2])\n",
    "        conting = chi2_contingency(ct)\n",
    "\n",
    "        stat_sub.append(conting[0])\n",
    "        pval_sub.append(conting[1])\n",
    "        dofs_sub.append(conting[2])\n",
    "        \n",
    "        n=ct.sum().sum()\n",
    "        corr_sub.append(np.sqrt(conting[0]/(len(df)*(min(ct.shape) - 1))))\n",
    "        \n",
    "    stat.append(stat_sub)\n",
    "    pval.append(pval_sub)\n",
    "    dofs.append(dofs_sub)\n",
    "    corr.append(corr_sub)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# #Comparaison 2 var quantitative\n",
    "# correl = pearsonr(df['Nombre_avis_publie'],df['Note'])\n",
    "# print(correl)\n",
    "\n",
    "\n",
    "\n",
    "# #Comparaison 2 variables qualitatives:\n",
    "# ct = pd.crosstab(df['Date_experience'],df['Note'])\n",
    "\n",
    "# conting = chi2_contingency(ct)\n",
    "\n",
    "# print(f'Statistique du test {conting[0]}, p-value du test {conting[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "figcorr = sns.heatmap(np.array(corr),annot=True,cmap='RdBu_r')\n",
    "\n",
    "figcorr.set_xticklabels(catVar)\n",
    "figcorr.set_yticklabels(catVar)\n",
    "figcorr.xaxis.tick_top()\n",
    "plt.xticks(rotation=45)\n",
    "plt.xticks(ha='left')\n",
    "plt.yticks(rotation=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
